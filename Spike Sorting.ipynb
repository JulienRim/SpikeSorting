{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b421dd-2c9f-4d35-840a-0d88cd54e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tdt\n",
    "import os\n",
    "import pywt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "import seaborn as sns\n",
    "\n",
    "from Struct_class import *\n",
    "from scipy import signal, integrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6879e13-5b88-46d7-83fc-7259eaeca58a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Alexandria\\\\Documents\\\\GitHub\\\\SpikeSorting/Raw Data/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\ALEXAN~1\\AppData\\Local\\Temp/ipykernel_20856/4187974918.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'{}/Raw Data/'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\Alexandria\\\\Documents\\\\GitHub\\\\SpikeSorting/Raw Data/'"
     ]
    }
   ],
   "source": [
    "rats = os.listdir('{}/Raw Data/'.format(os.getcwd()))\n",
    "\n",
    "i=0\n",
    "rat = rats[i]\n",
    "\n",
    "blocks = os.listdir('{}/Raw Data/{}'.format(os.getcwd(), rat))\n",
    "print(rat, blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889efda9-2985-4acb-ac39-78d56e15fad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "block = blocks[1]\n",
    "data = Struct(tdt.read_block('Raw Data/{}/{}'.format(rat, block)))\n",
    "data.preprocess()\n",
    "\n",
    "fs = data.streams.SU_3.fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b39561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_to_ms(num, fs):\n",
    "    \"\"\"\n",
    "    Converts each data point to a time in miliseconds.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    num : int, float or arrary\n",
    "        Contains the data being converted to a time\n",
    "        \n",
    "    fs : float\n",
    "        The sampling frequency\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    return : numpy array\n",
    "        Contains the time data\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(num) is int:\n",
    "        return num * (1000 / fs)\n",
    "    elif type(num) is np.ndarray or type(num) is list:\n",
    "        return np.array([(n * 1000 / fs) for n in num])\n",
    "    else:\n",
    "        print('Invalid Inputs, Returning Original Input.')\n",
    "        return num\n",
    "    \n",
    "def ms_to_samples(ms, fs):\n",
    "    \"\"\"\n",
    "    Converts each time in miliseconds to data points\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    ms : int, float or arrary\n",
    "        Contains the time being converted to data\n",
    "        \n",
    "    fs : float\n",
    "        The sampling frequency\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    return : numpy array\n",
    "        Contains the data points\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(ms) is int:\n",
    "        return ms * (1 / 1000) * fs\n",
    "    elif type(ms) is np.ndarray or type(ms) is list:\n",
    "        return np.array([m * (1 / 1000) * fs for m in ms])\n",
    "    else:\n",
    "        print('Invalid inputs, Returning Original Input.')\n",
    "        return ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfa7263-a539-49eb-aaf9-ccf94852c05d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_signal(data, filter_type = 'bp', low_freq = 300, high_freq = 6000, filter_order = 5):\n",
    "    \"\"\"\n",
    "    Filter the signal according to some specifications. \n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    data : Struct class (from Struct_class.py)\n",
    "        Contains a block of preprocessed data from TDT\n",
    "        \n",
    "    filter_type : string\n",
    "        The type of Butterworth filter to use.\n",
    "        Must be 'hp' for highpass, or 'bp' for bandpass\n",
    "        It will default to 'bp'\n",
    "    \n",
    "    low_freq : float\n",
    "        high-pass frequency of the bandpass or highpass filter.\n",
    "        \n",
    "    high_freq : float\n",
    "        Low-pass frequency of the bandpass filter\n",
    "        \n",
    "    filter_order : int\n",
    "        Order of the Butterworth filter to use\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    filtered_trace : numpy array\n",
    "        Filtered trace of signal\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract useful parameters\n",
    "    trace = data.streams.SU_3.data\n",
    "    fs = data.streams.SU_3.fs\n",
    "    \n",
    "    # Filter the data\n",
    "    if filter_type == 'hp':\n",
    "        b, a = signal.butter(filter_order, low_freq, btype=filter_type, fs=fs)\n",
    "    else:\n",
    "        b, a = signal.butter(filter_order, [low_freq, high_freq], btype=filter_type, fs=fs)\n",
    "    \n",
    "    filtered_trace = signal.lfilter(b, a, trace)\n",
    "    \n",
    "    return filtered_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142a4b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spike_thresholding(filtered_trace, nstdevs=4, direction = 'both', median_noise_filter=True):\n",
    "    \"\"\"\n",
    "    This function will return snippets of the data that have spikes greater than a threshold determined by \n",
    "    a number of standard deviations. \n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    filtered_trace : numpy array\n",
    "        Trace of signal after it was been filtered (output of the filter_signal function)\n",
    "        \n",
    "    nstdevs : float or int\n",
    "        Number of standard deviations to use for the threshold of the data\n",
    "        Defaults to 4\n",
    "        \n",
    "     direction : string\n",
    "         The direction of the signal taken\n",
    "         Defaults to both\n",
    "         \n",
    "    median_noide_filter : bool\n",
    "        Determines which method will be used to find the threshold\n",
    "        Defualts to true\n",
    "     \n",
    "    Outputs\n",
    "    -------\n",
    "    spike_inds : numpy array\n",
    "        Contains the indices of the spikes which pass the threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    # Using the Equation from R. Quian Quiroga\n",
    "    # NB: sigma = median(abs(filtered_trace)/0.6745)\n",
    "    if median_noise_filter:\n",
    "        threshold = nstdevs * np.median(abs(filtered_trace)/0.6745)\n",
    "    \n",
    "    else: #Standard deviation threshold\n",
    "        threshold = nstdevs * np.std(filtered_trace)\n",
    "    \n",
    "    # Direction of threshold\n",
    "    if direction =='positive' or direction == 'Positive':\n",
    "        spike_inds = np.where(filtered_trace >= threshold)[0]\n",
    "\n",
    "    elif direction == 'negative' or direction == 'Negative':\n",
    "        spike_inds = np.where(filtered_trace <= -threshold)[0]\n",
    "\n",
    "    else: # Both\n",
    "        spike_inds = np.where(np.abs(filtered_trace) >= threshold)[0]\n",
    "            \n",
    "    # Find successive points and add zero to array\n",
    "    non_successive = np.insert(np.where(np.diff(spike_inds) > 1)[0] + 1, 0, 0)\n",
    "\n",
    "    # Get a list of successive points found by thresholding and create a zipped array that has the start/stop of successive\n",
    "    # points above or below the threshold\n",
    "    zipped = np.asarray(list(zip([spike_inds[non_successive[:-1]], spike_inds[non_successive[1:]-1]]))).squeeze().T\n",
    "\n",
    "    # Only keep max indices\n",
    "    spike_inds = np.array([a + np.argmax(np.abs(filtered_trace[a:b+1])) for a, b in zipped])\n",
    "    \n",
    "    return spike_inds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a03eb77-17d4-4fb9-9029-be776a3f0d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to give windows\n",
    "def get_spike_traces(filtered_trace, spike_inds, wstart=20, wend=44):\n",
    "    \"\"\"\n",
    "    This function will return the values of the spikes who indices cross the threshold.\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    filtered_trace : numpy array\n",
    "        Trace of signal after it was been filtered (output of the filter_signal function)\n",
    "    \n",
    "    spike_inds : numpy array\n",
    "        Contains the indexes of the spikes which pass the threshold (output of the spike_thresholding function)\n",
    "        \n",
    "    wstart : int\n",
    "        Where the spike is centered\n",
    "        Defaults to 20\n",
    "    \n",
    "    wend : int\n",
    "        Where the window ends relative to the center\n",
    "        Defaults to 44\n",
    "        \n",
    "    Outputs\n",
    "    -------\n",
    "    spike_traces : numpy array\n",
    "        Contains the values of the spikes which passed the threshold\n",
    "    \"\"\"\n",
    "    \n",
    "    spike_traces = np.empty((len(spike_inds), wstart + wend))\n",
    "    \n",
    "    for i in range(len(spike_inds)):\n",
    "        start = spike_inds[i] - wstart\n",
    "        stop = spike_inds[i] + wend\n",
    "        try:\n",
    "            spike_traces[i] = filtered_trace[start:stop]\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return spike_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506a3571",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_signal = filter_signal(data, low_freq=300, high_freq=6000, filter_order=5)\n",
    "spike_inds = spike_thresholding(filtered_signal, nstdevs=4, direction='positive')\n",
    "spike_traces = get_spike_traces(filtered_signal, spike_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8aac333",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(spike_inds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75447e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots the trace\n",
    "%matplotlib inline\n",
    "fig,ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for trace in spike_traces[::100]:\n",
    "    ax.plot(trace, alpha=0.5, color='#E0A4D1')\n",
    "    #ax.scatter(filtered_trace[spike_inds[i]], color='k', s=25)\n",
    "\n",
    "plt.axhline(y = 0, color = 'k', linestyle = '-') #Creates a visual for when the trace crosses zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a516023",
   "metadata": {},
   "source": [
    "### Zero Crossing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4120d9c6-fb3c-4284-b70b-eb9352216e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zcr_features(spike_traces, wstart=20):\n",
    "    \"\"\"\n",
    "    This fuction performs zero crossing feature extraction on the trace\n",
    "    See Computationally Efficient Neural Feature Extraction for Spike Sorting in Implantable High-Density Recording Systems\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    spike_traces : numpy array\n",
    "        Contains the values of the spikes which passed the threshold (output of the get_spike_traces function)\n",
    "\n",
    "    wstart : int\n",
    "        Where the spike is centered\n",
    "        Defaults to 20\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    ZC1s : numpy array\n",
    "        Sum of values before the first zero crossing of the spike after wstart\n",
    "        \n",
    "    ZC2s : numpy array \n",
    "        Sum of values after the first zero crossing of the spike after wstart\n",
    "    \"\"\"\n",
    "    \n",
    "    # NB fix this if using negative and positive\n",
    "    ZC1s = np.empty(len(spike_traces))\n",
    "    ZC2s = np.empty_like(ZC1s)\n",
    "\n",
    "    for i in range(len(spike_traces)):\n",
    "        trace = spike_traces[i]\n",
    "        try:\n",
    "            Z_index = np.where(trace[wstart:] <= 0)[0][0] + wstart\n",
    "        except:\n",
    "            Z_index = len(trace)\n",
    "        ZC1s[i] = np.sum(trace[:Z_index])\n",
    "        ZC2s[i] = np.sum(trace[Z_index:])\n",
    "        \n",
    "    return ZC1s, ZC2s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4947c4f5-1609-44a1-a2de-305a9966ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "ZC1s, ZC2s = zcr_features(spike_traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b60fd4-438b-496d-a19f-e7e598fd73f0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plots the zero crossing feature extraction\n",
    "%matplotlib widget\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.scatter(ZC1s, ZC2s, s=.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbda0641",
   "metadata": {},
   "source": [
    "### Amplitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1503b07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def amplitude(spike_traces):\n",
    "    \"\"\"\n",
    "    This fuction performs amplitude feature extraction on the trace\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    spike_traces : numpy array\n",
    "        Contains the values of the spikes which passed the threshold (output of the get_spike_traces function)\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    max_amp : numpy array\n",
    "        The maximum amplitudes of the traces\n",
    "        \n",
    "    min_amp : numpy array \n",
    "        The minimum amplitudes of the traces\n",
    "        \n",
    "    amp_range : numpy array\n",
    "        The diffence between the maximum and minimum amplitudes of the trace\n",
    "    \"\"\"\n",
    "\n",
    "    # Positive Peak Amplitude\n",
    "    max_amp = np.empty(len(spike_traces))\n",
    "    for i in range(len(spike_traces)):\n",
    "        max_amp[i] = np.max(spike_traces[i])\n",
    "\n",
    "    # Negative Peak Amplitude\n",
    "    min_amp = np.empty(len(spike_traces))\n",
    "    for i in range(len(spike_traces)):\n",
    "        min_amp[i] = np.min(spike_traces[i])\n",
    "\n",
    "    # Amplitude Range (Peak-to-Valley Amplitude)\n",
    "    amp_range = abs(max_amp) + abs(min_amp)\n",
    "    \n",
    "    return max_amp, min_amp, amp_range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8557b040",
   "metadata": {},
   "source": [
    "### Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abd8146",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def width(spike_traces):\n",
    "    \"\"\"\n",
    "    This fuction performs width feature extraction on the trace\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    spike_traces : numpy array\n",
    "        Contains the values of the spikes which passed the threshold (output of the get_spike_traces function)\n",
    "    \n",
    "    Outputs\n",
    "    -------\n",
    "    pv_width : numpy array\n",
    "        The width in units of time from the peak to the valley of the traces\n",
    "    \"\"\"\n",
    "\n",
    "    # Peak-to-Valley Width\n",
    "    pos_index = np.empty(len(spike_traces))\n",
    "    neg_index = np.empty_like(pos_index)\n",
    "\n",
    "    for i in range(len(spike_traces)):\n",
    "        pos_index[i] = np.argmax(spike_traces[i])\n",
    "        neg_index[i] = np.argmin(spike_traces[i, 20:]) + 20\n",
    "\n",
    "    return pv_width = samples_to_ms(neg_index - pos_index, fs) # Converted to ms, therefore it's a waveform duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bb8f06",
   "metadata": {},
   "source": [
    "### Gradient (Deflection, Slope)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e23bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(spike_traces, max_amp, min_amp, pv_width, distance=10):\n",
    "    \"\"\"\n",
    "    This fuction performs gradient (slope) feature extraction on the trace\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    spike_traces : numpy array\n",
    "        Contains the values of the spikes which passed the threshold (output of the get_spike_traces function)\n",
    "        \n",
    "    max_amp : numpy array\n",
    "        The maximum amplitudes of the traces (output of the amplitude function)\n",
    "        \n",
    "    min_amp : numpy array \n",
    "        The minimum amplitudes of the traces (output of the amplitude function)\n",
    "    \n",
    "    pv_width : numpy array\n",
    "        The width in units of time from the peak to the valley of the traces (output from width function)\n",
    "        \n",
    "    distance : int\n",
    "        The number of indices taken on either side of the peak amplitude\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    slope_left : numpy array\n",
    "        The slope of the left side of the peak of the traces\n",
    "        \n",
    "    slope_right : numpy array\n",
    "        The slope of the right side of the peak of the traces\n",
    "        \n",
    "    slope : numpy array\n",
    "        The slope from the peak to the valley of the traces\n",
    "    \"\"\"\n",
    "\n",
    "    # Left Gradient\n",
    "    left = np.empty(len(spike_traces))\n",
    "    for i in range(len(spike_traces)):\n",
    "        left[i] = spike_traces[i][np.argmax(spike_traces[i]) - distance]\n",
    "    slope_left = (max_amp - left) / distance\n",
    "\n",
    "    # Right Gradient\n",
    "    right = np.empty(len(spike_traces))\n",
    "    for i in range(len(spike_traces)):\n",
    "        right[i] = spike_traces[i][np.argmax(spike_traces[i]) - distance]\n",
    "    slope_right = (max_amp - right) / distance\n",
    "\n",
    "    # Peak-to-Peak Gradient\n",
    "    slope = (min_amp - max_amp) / pv_width\n",
    "    \n",
    "    return slope_left, slope_right, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b6b1f",
   "metadata": {},
   "source": [
    "### Integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad6501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integration(spike_traces):\n",
    "    \"\"\"\n",
    "    This fuction performs integration feature extraction on the trace\n",
    "    \n",
    "    Inputs\n",
    "    ------\n",
    "    spike_traces : numpy array\n",
    "        Contains the values of the spikes which passed the threshold (output of the get_spike_traces function)\n",
    "\n",
    "    Outputs\n",
    "    -------\n",
    "    integration_trap : numpy array\n",
    "        The results of trapezoidal integration on the traces\n",
    "    \"\"\"\n",
    "\n",
    "    # Integration Over the Entire Signal Using the Trapezoidal Method\n",
    "    integration = np.empty(len(spike_traces))\n",
    "    for i in range(len(spike_traces)):\n",
    "        integration_trap[i] = integrate.trapz(spike_traces[i])\n",
    "\n",
    "    return integration_trap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
